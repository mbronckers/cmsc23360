{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "datapath = './Project3CommunityData'\n",
    "clean_data = 'clean_data'\n",
    "\n",
    "\n",
    "ping_cols = ['website', 'date', 'time', 'latency_times', 'latency_avg']\n",
    "#www.cnn.com,05-13-2020,10:00:01,12.8|16.9|8.73|8.61|7.37|7.72|8.63|7.27|15.1|8.29|8.37,9.98090909090909\n",
    "\n",
    "tr1_cols = ['website', 'date', 'time', 'hop_idx', 'hop_ip', 'latency1', 'latency2', 'latency3', 'latency_avg']\n",
    "# www.cnn.com,05-13-2020,10:00:01,1,(10.0.0.1),1.558,2.584,3.525,2.5556666666666668\n",
    "\n",
    "tr2_cols = ['website', 'date', 'time', 'hop_count']\n",
    "# www.cnn.com,05-16-2020,14:32:47,11\n",
    "\n",
    "api_cols = ['website', 'call', 'date', 'time', 'latency']\n",
    "# www.amazon.com,https://www.amazon.com/s?k=networks&ref=nb_sb_noss_2,05-13-2020,14:36:27,41.97399999999999\n",
    "\n",
    "pchar_agg_cols = ['website', 'date', 'time', 'hops']\n",
    "# en.wikipedia.org,05-13-2020,14:38:49,14\n",
    "\n",
    "pchar1_cols = ['website', 'date', 'time', 'hop_idx', 'dst', '?' ,'??']\n",
    "# en.wikipedia.org,05-13-2020,14:38:49,1,10.0.2.2,0.000000,0\n",
    "\n",
    "pchar2_cols = []\n",
    "# en.wikipedia.org,05-13-2020,14:38:49,0,10.0.2.15,-1,-1\n",
    "\n",
    "def col_selector(fileType):\n",
    "    switch = {\n",
    "        \"ping\": ping_cols,\n",
    "        \"tr1\": tr1_cols,\n",
    "        \"tr2\": tr2_cols,\n",
    "        \"api\": api_cols,\n",
    "        \"pchar_agg\": pchar_agg_cols,\n",
    "        \"pchar1\": pchar1_cols,\n",
    "        \"pchar2\": pchar2_cols\n",
    "    }\n",
    "    \n",
    "    return switch.get(fileType, \"ERROR FILETYPE NOT FOUND: \" + fileType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "teams = os.listdir(datapath)\n",
    "for team in teams:\n",
    "    data[team] = {}\n",
    "    for seq in ['seq1', 'seq2', 'seq3']:\n",
    "        data[team][seq] = {}\n",
    "        seq_path = datapath + '/' + team + '/clean_data/' + seq\n",
    "        for file in os.listdir(seq_path):\n",
    "            match = re.search('(.*)_(ping|tr1|tr2|pchar1|pchar2|pchar_agg|api)', file)\n",
    "            website = match.group(1)\n",
    "            fileType = match.group(2)\n",
    "            if not website in data[team][seq].keys(): \n",
    "                data[team][seq][website] = {}\n",
    "                \n",
    "            cols = col_selector(fileType)\n",
    "            df = pd.read_csv(seq_path + '/' + file, names = cols, header = 0)\n",
    "            data[team][seq][website][fileType] = df\n",
    "\n",
    "# All data is now read, can be indexed via data[team][seq#][website][fileType]\n",
    "# team: Team1...Team8\n",
    "# seq#: seq1, seq2, seq3\n",
    "# website: e.g. www_cnn_com\n",
    "# fileType: one of ping|tr1|tr2|pchar1|pchar2|pchar_agg|api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
